{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikeinterface Cookbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Recording and Sorting objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 3.43 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[0 1 2] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[ -25.   65.]\n",
       " [ -25.  -25.]\n",
       " [   0. -125.]\n",
       " [  25.  -25.]\n",
       " [  25.   65.]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    3.43 MiB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spikeinterface.core import generate_recording \n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10])\n",
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>NumpySorting: 3 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>[0 1 2] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul></ul></details>"
      ],
      "text/plain": [
       "NumpySorting: 3 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spikeinterface.core import generate_sorting \n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting channel names and unit IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.get_channel_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unit1', 'unit2', 'unit3'], dtype='<U5')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "sorting.get_unit_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a Recording and Sorting Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 2 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 2.29 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>['a' 'b'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[ -25.   65.]\n",
       " [ -25.  -25.]\n",
       " [   0. -125.]\n",
       " [  25.  -25.]\n",
       " [  25.   65.]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]]</details><details><summary> <strong> group </strong> </summary>[0 0]</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 2 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    2.29 MiB"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_sliced_recording = recording.select_channels(channel_ids=[\"a\", \"b\"])\n",
    "channel_sliced_recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>UnitsSelectionSorting: 2 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>['unit1' 'unit2'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul></ul></details>"
      ],
      "text/plain": [
       "UnitsSelectionSorting: 2 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_selected_sorting = sorting.select_units(unit_ids=[\"unit1\", \"unit2\"])\n",
    "unit_selected_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames / Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 1,000 samples - 0.03s (33.33 ms) - float32 dtype - 11.72 KiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>['a' 'b' 'c'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[ -25.   65.]\n",
       " [ -25.  -25.]\n",
       " [   0. -125.]\n",
       " [  25.  -25.]\n",
       " [  25.   65.]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 1,000 samples - 0.03s (33.33 ms) \n",
       "                    float32 dtype - 11.72 KiB"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_recording = recording.frame_slice(start_frame=0, end_frame=1000)\n",
    "sliced_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>FrameSliceSorting: 3 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>['unit1' 'unit2' 'unit3'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul></ul></details>"
      ],
      "text/plain": [
       "FrameSliceSorting: 3 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_sorting = sorting.frame_slice(start_frame=0, end_frame=1000)\n",
    "sliced_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating recordings (across time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import concatenate_recordings\n",
    "\n",
    "recording1 = generate_recording(num_channels=3, durations=[10])\n",
    "recording2 = generate_recording(num_channels=3, durations=[10])\n",
    "\n",
    "concanted_recordings = concatenate_recordings([recording1, recording2])\n",
    "\n",
    "assert concanted_recordings.get_duration() == recording1.get_duration()  + recording2.get_duration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating channels to a single recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import aggregate_channels\n",
    "\n",
    "recording1 = generate_recording(num_channels=3, durations=[10], set_probe=False)  # To avoid location check\n",
    "recording1 = recording1.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])\n",
    "recording2 = generate_recording(num_channels=2, durations=[10], set_probe=False)  \n",
    "recording2 = recording2.rename_channels(new_channel_ids=[\"d\", \"e\"])\n",
    "\n",
    "aggregated_recording = aggregate_channels([recording1, recording2])  \n",
    "assert aggregated_recording.get_num_channels() == 5\n",
    "assert list(aggregated_recording.get_channel_ids()) == ['a', 'b', 'c', 'd', 'e']  # Failing right now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of operations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![Recording Operations](./recording_operations.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we parallelize over\n",
    "\n",
    "![Chuking Description](./parallel_processing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to control paralell execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lenght of the chunk\n",
    "    * chunk_duration :  Lenght of the chunk in seconds\n",
    "    * chunk_size: Number of samples per chunk\n",
    "    * chunk_memory: Memory usage for each job\n",
    "    * total_memory Total memory usage \n",
    "* n_jobs: Number of jobs to use. With -1 the number of jobs is the same as number of cores\n",
    "* progress_bar: Whether to show a progress bar\n",
    "* mp_context: fork, span or forkserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0746f6f35d46b599c63a4b6fe84e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spikeinterface.core import generate_recording, write_binary_recording\n",
    "import tempfile\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10])\n",
    "\n",
    "\n",
    "job_kwargs = {\"n_jobs\":2, \"chunk_duration\": 5.0, \"progress_bar\": 1, 'progress_bar': True}\n",
    "\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.raw', delete=False) as temp_file:\n",
    "    temporary_file_path = temp_file.name\n",
    "    write_binary_recording(recording=recording, file_paths=[temporary_file_path], **job_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![job_kwargs](./job_kwargs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting global job_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_jobs': 1, 'chunk_duration': '1s', 'progress_bar': True, 'mp_context': None, 'max_threads_per_process': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/Documents/SpikeInterface/spikeinterface/src/spikeinterface/core/job_tools.py:103: UserWarning: `n_jobs` is not set so parallel processing is disabled! To speed up computations, it is recommended to set n_jobs either globally (with the `spikeinterface.set_global_job_kwargs()` function) or locally (with the `n_jobs` argument). Use `spikeinterface.set_global_job_kwargs?` for more information about job_kwargs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51803ff12996465e867b9df932a1d13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caac89cffab341c7b069e9d778b78529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spikeinterface import set_global_job_kwargs, get_global_job_kwargs\n",
    "from spikeinterface.core import generate_recording, write_binary_recording\n",
    "import tempfile\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10])\n",
    "\n",
    "\n",
    "print(get_global_job_kwargs())\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.raw', delete=False) as temp_file:\n",
    "    temporary_file_path = temp_file.name\n",
    "    write_binary_recording(recording=recording, file_paths=[temporary_file_path])\n",
    "\n",
    "\n",
    "set_global_job_kwargs(n_jobs=2, chunk_duration=5.0, progress_bar=True)\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.raw', delete=False) as temp_file:\n",
    "    temporary_file_path = temp_file.name\n",
    "    write_binary_recording(recording=recording, file_paths=[temporary_file_path])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop to mentioned cautionary tales:\n",
    "* Performance is highly dependent on the data, operations and the hardware.\n",
    "* The best way to optimize is to try different configurations and see what works best for your data and hardware.\n",
    "* Threading vs multiprocessing: Threading is generally faster for I/O bound tasks, while multiprocessing is better for CPU bound tasks.\n",
    "* Anything to add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Recording and Sorting Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "n_jobs=2 - samples_per_chunk=150,000 - chunk_memory=1.72 MiB - total_memory=3.43 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071e051f297447be9b73c2de69da1d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 3.43 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>['a' 'b' 'c'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[ -25.   65.]\n",
       " [ -25.  -25.]\n",
       " [   0. -125.]\n",
       " [  25.  -25.]\n",
       " [  25.   65.]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details><details><summary> <strong> a_property </strong> </summary>['value1' 'value2' 'value3']</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    3.43 MiB"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_recording\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10], set_probe=True)\n",
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "\n",
    "folder_path = Path(\"./test_recording\")\n",
    "\n",
    "\n",
    "binary_recording = recording.save_to_folder(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "binary_recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>NumpyFolder: 3 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>['unit1' 'unit2' 'unit3'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>a_property</strong></summary>['value1' 'value2' 'value3']</details></ul></details>"
      ],
      "text/plain": [
       "NumpyFolder: 3 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_sorting\n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "\n",
    "sorting.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "folder_path = Path(\"./test_sorting\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "binary_sorting = sorting.save_to_folder(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "binary_sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>UnitsSelectionSorting: 3 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>['unit1' 'unit2' 'unit3'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>a_property</strong></summary>['value1' 'value2' 'value3']</details></ul></details>"
      ],
      "text/plain": [
       "UnitsSelectionSorting: 3 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarr format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_zarr_recording \n",
      "n_jobs=2 - samples_per_chunk=150,000 - chunk_memory=1.72 MiB - total_memory=3.43 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2671e52a6922401f8cdf5e1f2282f3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_zarr_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 3.43 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>['a' 'b' 'c'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[-25.0, 65.0], [-25.0, -25.0], [0.0, -125.0], [25.0, -25.0], [25.0, 65.0]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li><li> <strong> compression_ratio </strong>: 1.1352649235304468</li><li> <strong> compression_ratio_segments </strong>: {0: 1.1352649235304468}</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details><details><summary> <strong> a_property </strong> </summary>['value1' 'value2' 'value3']</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    3.43 MiB"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_recording\n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10], set_probe=True)\n",
    "recording = recording.rename_channels(new_channel_ids=[\"a\", \"b\", \"c\"])  # This is not in-place\n",
    "recording.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "folder_path = Path(\"./test_recording.zarr\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "zarr_recording = recording.save_to_zarr(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "zarr_recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ecc3d52f98428db7e0f135867b1ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/', nodes=(Node(disabled=True, icon='table', name='channel_ids (3,) <U1'…"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_recording._root.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>ZarrSortingExtractor: 3 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>['unit1' 'unit2' 'unit3'] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>a_property</strong></summary>['value1' 'value2' 'value3']</details></ul></details>"
      ],
      "text/plain": [
       "ZarrSortingExtractor: 3 units - 1 segments - 30.0kHz"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_sorting\n",
    "\n",
    "sorting = generate_sorting(num_units=3, durations=[10])\n",
    "sorting = sorting.rename_units(new_unit_ids=[\"unit1\", \"unit2\", \"unit3\"])  # This is not in-place\n",
    "\n",
    "sorting.set_property(\"a_property\", [\"value1\", \"value2\", \"value3\"])  # This is in place\n",
    "\n",
    "\n",
    "folder_path = Path(\"./test_sorting.zarr\")\n",
    "\n",
    "job_kwargs={'progress_bar': True, \"verbose\":True, \"n_jobs\":2}\n",
    "zarr_sorting = sorting.save_to_zarr(folder=folder_path,  overwrite=True, **job_kwargs)   \n",
    "zarr_sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933af183eab249ac8a6495ed7ec9b312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/', nodes=(Node(disabled=True, name='properties', nodes=(Node(disabled=T…"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_sorting._root.tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving is portable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "n_jobs=2 - samples_per_chunk=150,000 - chunk_memory=1.72 MiB - total_memory=3.43 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11500108c6444a8b9db02327f2462f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 3.43 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[0 1 2] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[-25.0, 65.0], [-25.0, -25.0], [0.0, -125.0], [25.0, -25.0], [25.0, 65.0]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    3.43 MiB"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from spikeinterface.core import generate_recording\n",
    "from spikeinterface.core import load_extractor  \n",
    "\n",
    "recording = generate_recording(num_channels=3, durations=[10], set_probe=True)\n",
    "\n",
    "\n",
    "# Save a recording within a nested folder\n",
    "base_folder = Path.cwd() / \"saving_recording_and_moving\" \n",
    "original_recording_folder = base_folder / \"folderA\" / \"recording_folder\"  \n",
    "\n",
    "recording = recording.save_to_folder(folder=original_recording_folder, overwrite=True)\n",
    "\n",
    "\n",
    "# We move the folder from its original location one level up to the current folder\n",
    "another_folder = base_folder / \"folderB\"\n",
    "another_folder.mkdir(exist_ok=True)\n",
    "destination_folder = another_folder / \"recording_folder\"\n",
    "\n",
    "original_recording_folder.rename(destination_folder)\n",
    "\n",
    "\n",
    "\n",
    "load_extractor(file_or_folder_or_dict=destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving preprocessing provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording \n",
      "n_jobs=2 - samples_per_chunk=150,000 - chunk_memory=1.72 MiB - total_memory=3.43 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfe8e05b8d84d498c1ebbd4dfc56a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This generated an error because the references to the raw data were absolute\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype - 3.43 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[0 1 2] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> probe_0_planar_contour </strong>: [[-25.0, 65.0], [-25.0, -25.0], [0.0, -125.0], [25.0, -25.0], [25.0, 65.0]]</li><li> <strong> probes_info </strong>: [{}]</li><li> <strong> name </strong>: SyntheticRecording</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> contact_vector </strong> </summary>[(0, 0.,  0., 'circle', 6., '', '0', 0, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 20., 'circle', 6., '', '1', 1, 'um', 1., 0., 0., 1.)\n",
       " (0, 0., 40., 'circle', 6., '', '2', 2, 'um', 1., 0., 0., 1.)]</details><details><summary> <strong> location </strong> </summary>[[ 0.  0.]\n",
       " [ 0. 20.]\n",
       " [ 0. 40.]]</details><details><summary> <strong> group </strong> </summary>[0 0 0]</details></ul></details>"
      ],
      "text/plain": [
       "SyntheticRecording: 3 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float32 dtype \n",
       "                    3.43 MiB"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from spikeinterface.core import generate_recording, load_extractor\n",
    "from spikeinterface.preprocessing import bandpass_filter, common_reference\n",
    "\n",
    "# First we simulate having raw data (can be large!) in a folder \n",
    "simulated_recording = generate_recording(num_channels=3, durations=[10])\n",
    "base_folder = Path.cwd() / \"working_with_preprocessing_provenance\"\n",
    "\n",
    "raw_data_location = base_folder/ \"raw_data_location_folder\"\n",
    "raw_data_location.mkdir(parents=True, exist_ok=True)\n",
    "recording_saved = simulated_recording.save(folder=raw_data_location, overwrite=True)\n",
    "\n",
    "\n",
    "# Now our common analysis pipeline starts by loading the raw data\n",
    "raw_data_recording = load_extractor(file_or_folder_or_dict=raw_data_location)\n",
    "# And then we apply some preprocessing steps\n",
    "recording_preprocessed = bandpass_filter(common_reference(raw_data_recording))\n",
    "\n",
    "# Note that we can save our preprocessed data for faster access afterwards:\n",
    "# recording_preprocessed.save(folder=Path.cwd() / \"preprocessed_data_folder\")\n",
    "# But maybe we only want to save our provenance data, that is, our pre-processing pipeline and parameters\n",
    "# For this we can save oure preprocessing pipeline as a json file\n",
    "\n",
    "# dump_to_json without relative_to\n",
    "\n",
    "json_file_path = base_folder / \"analysis_folder\" / \"preprocessed_pipeline.json\"\n",
    "recording_preprocessed.dump_to_json(file_path=json_file_path)\n",
    "\n",
    "\n",
    "json_file_path_relative = base_folder / \"analysis_folder\" / \"preprocessed_pipeline_relative.json\"\n",
    "recording_preprocessed.dump_to_json(file_path=json_file_path_relative, relative_to=base_folder)\n",
    "\n",
    "\n",
    "# This then can be loaded again to recover the pipeline\n",
    "recovered_pipeline = load_extractor(file_or_folder_or_dict=json_file_path)\n",
    "\n",
    "# We move the json to a new folder\n",
    "new_base_folder = Path.cwd() / \"new_working_with_preprocessing_provenance\"\n",
    "new_base_folder.mkdir(exist_ok=True)\n",
    "\n",
    "base_folder.rename(new_base_folder)\n",
    "\n",
    "new_json_file_path = new_base_folder / \"analysis_folder\" / \"preprocessed_pipeline.json\"\n",
    "assert new_json_file_path.is_file(), \"The json file was not moved correctly\" \n",
    "\n",
    "# Try to load it\n",
    "try:\n",
    "    recovered_pipeline = load_extractor(file_or_folder_or_dict=new_json_file_path)\n",
    "except:\n",
    "    print(\"This generated an error because the references to the raw data were absolute\")\n",
    "    \n",
    "# We can solve this by saving the json file with relative paths\n",
    "\n",
    "new_json_file_path_with_relative = new_base_folder / \"analysis_folder\" / \"preprocessed_pipeline_relative.json\"\n",
    "assert new_json_file_path_with_relative.is_file(), \"The json file with relative was not moved correctly\"\n",
    "recovered_pipeline = load_extractor(file_or_folder_or_dict=new_json_file_path_with_relative, base_folder=new_base_folder)\n",
    "recovered_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
