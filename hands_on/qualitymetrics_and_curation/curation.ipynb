{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a68793-9915-4b04-b5ef-a9e5e67d0079",
   "metadata": {},
   "source": [
    "## Quality metrics and Curation modules\n",
    "\n",
    "In this workshop, we will take a look at how to curate the output of a spike-sorting analyses using the `curation` and `qualitymetrics` modules.\n",
    "\n",
    "The dataset we will be using is a cerebellar cortex recording (cut down to 5 minutes and 26 channels) analyzed with Kilosort 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a31718-fe1f-4cbb-84bb-7e96233bf5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import spikeinterface.core as si\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74ed75-498a-4547-99b9-292050ed2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5cc54-2e04-494b-bd65-17878e758b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(\"../../SpikeInterface Dataset Tutorial/\")\n",
    "curation_dataset = base_folder / \"dataset_curation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2fbe4-e80b-4377-b904-063c77824a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = si.load_extractor(curation_dataset / \"curation_recording\")\n",
    "sorting = si.load_extractor(curation_dataset / \"curation_sorting\")\n",
    "\n",
    "print(recording)\n",
    "print(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52cacc2-6fc8-4889-a2dd-8615c62aa106",
   "metadata": {},
   "source": [
    "Before analyzing our output, we can perform a fast curation:\n",
    "- Remove any duplicated spikes (spikes happening less than 0.3ms apart)\n",
    "- Remove excess spikes (kilosort sometimes outputs spikes hapenning out of the recording bounds)\n",
    "- Remove redundant units (high fraction of shared spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440653c9-2166-4b6a-b6ce-479fe491edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = scur.remove_duplicated_spikes(sorting, censored_period_ms=0.3, method=\"keep_first_iterative\")\n",
    "sorting = scur.remove_excess_spikes(sorting, recording)\n",
    "sorting = scur.remove_redundant_units(sorting, align=False, remove_strategy=\"max_spikes\")\n",
    "sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01fd16d-22d2-4367-acd7-adf972ec6bbc",
   "metadata": {},
   "source": [
    "We still have 52 units (on redundants in this dataset), but probably not all of them are really good!\n",
    "\n",
    "Let's create a `SortingAnalyzer` to start looking at out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811673a2-3071-4c63-8278-4a6b868516c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_f = spre.bandpass_filter(recording, freq_min=120, freq_max=8000, filter_order=2, ftype=\"bessel\")\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(sorting, recording_f, format=\"memory\", sparse=False)\n",
    "analyzer.compute({\n",
    "    'noise_levels': {},\n",
    "    'random_spikes': {'max_spikes_per_unit': 1_000},\n",
    "    'templates': {'ms_before': 1.5, 'ms_after': 3.5},\n",
    "    'spike_amplitudes': {},\n",
    "    'correlograms': {'bin_ms': 0.5}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d6885-54b9-48ab-b442-cd38f14269d9",
   "metadata": {},
   "source": [
    "Let's look at the most basic metric: the average firing rate (in Hz) of our units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898edf5-8a37-452c-b7d8-f7a415332e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqm.compute_firing_rates(analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112e919-43f5-4d02-b136-a32004c917b5",
   "metadata": {},
   "source": [
    "We can see that the firing rate varies a lot, with some units being below 0.5 Hz (probably bad units), and some units above 100 Hz (not uncommon for Purkinje cells simple spikes).\n",
    "\n",
    "We can compute all of SpikeInterface quality metrics with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271e623-0aae-4009-8006-e83450bf8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics = sqm.compute_quality_metrics(analyzer)\n",
    "quality_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f3a55-ee58-4aea-97b3-d1cd78a0bc7a",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of metrics (some containing redundant information).\n",
    "For demonstration purposes, we will focus on 4 of those metrics (which I use all the time):\n",
    "- `firing_rate`: The mean firing rate (in Hz). The total number of spikes divided by the duration of the recording. This helps a lot for classifying units (knowing the cell type) and to find aberrant units.\n",
    "- `SNR`: The Signal-to-Noise Ratio (amplitude of the spike divided by the noise level). A low SNR (< 3) is usually problematic.\n",
    "- `rp_contamination`: Contamination (i.e. $FP \\over TP+FP$) estimation by looking at the refractory period violations. Makes the hypothesis that the contaminant spikes happen at random.\n",
    "- `sd_ratio`: The ratio between the standard deviation of spike amplitudes and the noise level. Under the assumption that all spikes have the same shape, this ratio should be $1.0$. Several safeguards are included to remove effects of drift, bursting ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb833af-ef00-48db-8443-3c89e8d94bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics = quality_metrics[[\"firing_rate\", \"snr\", \"rp_contamination\", \"sd_ratio\"]]\n",
    "quality_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc607c93-da5d-47d1-8f8e-b5fd9856a28d",
   "metadata": {},
   "source": [
    "From having looked at the dataset extensively, I know what units are very good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adcbc2-3cf2-4a28-bfa0-e50eee634936",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_unit_ids = np.array([3, 13, 19, 34, 39, 40, 41], dtype=np.int32)\n",
    "ok_unit_ids = np.array([11, 18, 22, 51], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d85a1-7be6-4e75-a753-354074ecc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics.loc[good_unit_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294f75e-f3ba-4033-8b6a-9473ea44855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_metrics.loc[ok_unit_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432d524-7f2e-4ecd-b70d-90e11cb7185c",
   "metadata": {},
   "source": [
    "Looking at the metrics on the good units, we can create rules to only keep units that are of sufficient quality. For example:\n",
    "- A `firing_rate` greater than 1.0 Hz\n",
    "- A `snr` greater than 1.1\n",
    "- A `rp_contamination` below 20%\n",
    "- A `sd_ratio` below 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cb871-21ce-4f8c-8d3b-ade459e8aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = \"firing_rate > 1.0 & snr > 1.1  & rp_contamination < 0.2 & sd_ratio < 1.5\"\n",
    "good_metrics = quality_metrics.query(rule)\n",
    "\n",
    "curated_unit_ids = list(good_metrics.index)\n",
    "print(curated_unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65c284-3c17-49ea-88cb-4bd53e89086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_sorting = sorting.select_units(curated_unit_ids)\n",
    "curated_analyzer = analyzer.select_units(curated_unit_ids)\n",
    "\n",
    "curated_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d8d43-e101-4ba8-b7f3-02f69ff3e93b",
   "metadata": {},
   "source": [
    "We removed half of the units in the Kilosort output! (we started with 52).\n",
    "\n",
    "The metrics and thresholds used will, of course, depend on the recording type, and need to be tuned.\n",
    "After tuning, we can have a powerful automated curation, that is not perfect, but removes a lot of the obviously garbage units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a20c5-9636-4a97-bad3-1cd86ad5c796",
   "metadata": {},
   "source": [
    "The `curation` module also offers a method to find split units, that you can inspect and decide whether you want to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c953b0-3bbd-4fe4-8109-8467fa001a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = scur.get_potential_auto_merge(curated_analyzer)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fb7f6-a84f-40e9-b96e-22e505ec7706",
   "metadata": {},
   "source": [
    "We can see that the merge function found a pair that is potentially a good merge.\n",
    "\n",
    "We can check it by plotting the correlograms and templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d4c2f-78d9-46fa-9f60-f5d1d86a604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    sw.plot_crosscorrelograms(analyzer, unit_ids=pair, min_similarity_for_correlograms=None, backend=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d1a6e-36ea-4e7f-bfa9-9ee9bd6e8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_for_plot = si.estimate_sparsity(recording_f, sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac339df-b84d-48d8-a3ab-e598dadb3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_templates(analyzer, unit_ids=pair, sparsity=sparsity_for_plot, unit_colors={pair[0]: \"r\", pair[1]: \"b\"}, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9754bb-8406-4ab6-ac3a-618cb22384ee",
   "metadata": {},
   "source": [
    "Indeed, the correlograms and templates seem to match!\n",
    "\n",
    "We can thus create a script to merge the units together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831528cd-afc6-4ce2-9336-040caf52d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_sorting = scur.CurationSorting(curated_sorting)\n",
    "curation_sorting.merge(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7423a-0d13-4f73-af0d-320e4444fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_sorting.sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547fd37-b824-4dda-ac34-f6e69065ea2c",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In the `auto_merge` function, two important parameters are:\n",
    "- The `corr_diff_thresh` (0.16 by default). The maximum accepted difference between the correlograms\n",
    "- The `template_diff_thresh` (0.25 by default). The maximum accepted difference between the templates\n",
    "\n",
    "Increase these values to see if you can find new pairs that are potential merges, and check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647e8e2-f1c9-4049-a41f-c7bb5115b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
