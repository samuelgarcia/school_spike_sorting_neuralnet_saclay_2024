{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890b59dc-9449-4f51-aa1b-32010278e98c",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this tutorial we will show how to construct a preprocessing pipeline to \"prepare\" your recording prior to spike sorting.\n",
    "While some of the steps that we'll see are Neuropixels specific, most of the concepts can be applied to any probe device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4e0a2-7ec6-4754-9ca1-7dddcb2dbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c702f-c564-45f2-aa48-9696b450cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91889e0-6a51-4bb4-b9be-a03fd0976667",
   "metadata": {},
   "source": [
    "## \"Destriping\" the raw traces\n",
    "\n",
    "Neuropixels probes (and similar) have long shanks that can experience noise that appear as \"stripes\".\n",
    "This section shows how to clean the signals and remove bad channels prior to spike sorting.\n",
    "\n",
    "To demonstrate this, we are going to use some test datasets shared by Olivier Winter from IBL.\n",
    "\n",
    "For more information, please refer to the IBL paper:\n",
    "\n",
    "[Spike sorting pipeline for the International Brain Laboratory, ](https://figshare.com/articles/online_resource/Spike_sorting_pipeline_for_the_International_Brain_Laboratory/19705522/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e2853-ccca-4689-b9dd-b2f35200fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(\"../../SpikeInterface Dataset Tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbbafe-1b4e-4a31-8bde-cd658b860483",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_folder = base_folder / \"dataset_preprocessing\"\n",
    "destriping_folder = preprocessing_folder / \"destriping\"\n",
    "session = \"8413c5c6-b42b-4ec6-b751-881a54413628\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea260c-e0bb-4e3b-9b69-26b9b12357d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibl_data_cbin_file = [p for p in (destriping_folder / session).iterdir() if p.name.endswith(\".ap.cbin\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a028d1-d72d-4717-bdee-68379417e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.read_cbin_ibl(cbin_file=ibl_data_cbin_file)\n",
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9ebe-924c-487e-82e1-9fb447230735",
   "metadata": {},
   "source": [
    "Let's first take a look at the \"raw\" traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f98c2e-905d-4f2d-93e9-652a92df7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_traces(recording, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4693fc-8fe5-43b3-b9e9-6b3d6a3da4e8",
   "metadata": {},
   "source": [
    "We notice there are both some horizontal and vertical \"stripes\", plus some \"patterns\".\n",
    "\n",
    "Although Neuropixels data have a hardware highpass filter (cutoff at 150Hz), there can be come leftover content from the LFP frequency band.\n",
    "\n",
    "So let's first highpass the data and see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9760414-3780-4ba8-85b5-e9f4f6f391f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_hp = spre.highpass_filter(recording)\n",
    "\n",
    "# we can visualize multiple \"layers\" at the same time!\n",
    "recording_layers = dict(\n",
    "    raw=recording,\n",
    "    highpass=recording_hp\n",
    ")\n",
    "w = sw.plot_traces(recording_layers, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c07f1-c945-4b31-b556-e5e1172a3803",
   "metadata": {},
   "source": [
    "Now the \"patterns\" are mainly gone, but we can still see some vertical artefacts and some horizontal lines.\n",
    "\n",
    "While the vertical lines can be attributed to transient external noise, the horizontal ones are mainly due to a channel either being too silent (\"dead\") or too \"noisy\".\n",
    "\n",
    "(In addition, on the top of the probe we can observe an area of faint activity. This could indicate that the recording area is not fully in the brain, which could happen when targeting surface area.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5eae34-0c36-4b26-8af1-eb17934c455f",
   "metadata": {},
   "source": [
    "### Phase shift\n",
    "\n",
    "Neuropixels probes can record from 384 channels simultaneously, but the analog-to-digital converters (ADCs) of the probe are only 32!\n",
    "\n",
    "**This means that channels are not sampled exactly at the same time!**\n",
    "\n",
    "Within a sampling cicle (1/30kHz = 33$\\mu$s), each ADC sweeps and samples a group of channels. While this misalignment could sound small, it could affect processing steps, such as common median reference.\n",
    "\n",
    "The delay of each channel is automatically loaded as the `inter_sample_shift` property (when reading the data with the `read_spikeglx` or `read_openephys`), which tells what is the shift between 0 (beginning of the cycle) and 1 (end of the cycle) which each channel is sampled at by the ADC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b2482-f9b9-4b67-a28d-31af55a3df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording.get_property(\"inter_sample_shift\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c189d-2062-420a-a8bd-a0559781dc2e",
   "metadata": {},
   "source": [
    "To correct for this shift, we can use the `spre.phase_sift()` function. This function internally uses a Fourier Transform to align each channel according to its sample shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116853c-92ab-427b-bac9-50c6e5759a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_ps = spre.phase_shift(recording_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13640e38-c5c5-42d5-88a7-51303ce8f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_layers = dict(\n",
    "    highpass=recording_hp,\n",
    "    phase_shift=recording_ps\n",
    ")\n",
    "w = sw.plot_traces(recording_layers, time_range=[0.23, 0.25], backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5319fea-199f-4b7c-ae6c-b382eecc9b40",
   "metadata": {},
   "source": [
    "### Detect and remove bad channels\n",
    "\n",
    "We still observe some horizontal bands, whcih suggests the presence of bad channels.\n",
    "\n",
    "The `spre.detect_bad_channels()` function uses several strategies (including coherence along depth, PSD energy) to label channels as:\n",
    "- \"good\"\n",
    "- \"dead\": the signal is too weak\n",
    "- \"noisy\": the signal is too strong\n",
    "- \"out\": channels outside of the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510acbff-d988-46fc-ae67-5e87b91cce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_channel_ids, channel_labels = spre.detect_bad_channels(recording_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85399028-ec82-4a6a-a457-a1d9c871cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(channel_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab456-c58f-4856-bebd-c0a4f84df119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, count in zip(labels, counts):\n",
    "    print(f\"Found {count} channels with label {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ba9fd-3a7a-4f31-9ee9-c8152be623de",
   "metadata": {},
   "source": [
    "Let's remove the \"bad channels\" with the `remove_channels` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326f799-1aad-4b92-bcb4-c93fce122480",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_hp_rm = recording_hp.remove_channels(bad_channel_ids)\n",
    "recording_ps_rm = recording_ps.remove_channels(bad_channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b83093-0b18-45da-808f-6dc439a28432",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531e1a8-5e89-48df-bcb5-9c3afd07bb8f",
   "metadata": {},
   "source": [
    "Now that the channels are aligned, we can use some denoisers to remove these \"common mode\" noisy events. \n",
    "\n",
    "One option is to use the `spre.common_reference` function, which removes the median of the channel at each sample.\n",
    "Another option, again developed by IBL, is to apply a highpass filter, but in the \"space\" dimension, i.e., across depth (`spre.highpass_spatial_filter`).\n",
    "\n",
    "Let's apply these steps with and without `phase_shift` to see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f69c6-2b20-4b79-831e-b99dd35defa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr_no_ps = spre.common_reference(recording_hp_rm)\n",
    "recording_cmr_ps = spre.common_reference(recording_ps_rm)\n",
    "recording_hps_no_ps = spre.highpass_spatial_filter(recording_hp_rm)\n",
    "recording_hps_ps = spre.highpass_spatial_filter(recording_ps_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806fc29-b95c-4a7b-be31-20390390951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_layers = dict(\n",
    "    cmr_no_ps=recording_cmr_no_ps,\n",
    "    cmr_ps=recording_cmr_ps,\n",
    "    hps_no_ps=recording_hps_no_ps,\n",
    "    hps_ps=recording_hps_ps,\n",
    ")\n",
    "w = sw.plot_traces(recording_layers, time_range=[0.23, 0.25], backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a2a01-313a-41b0-80dd-a7aeecf14bcd",
   "metadata": {},
   "source": [
    "Both CMR and highpass spatial filtering do a good job in removing the vertical stripes, but phase shift is necessary!\n",
    "\n",
    "**Note**: the highpass spatial filter behaves better than CMR if the vertical stripes are not even across channels. However, its application might make the spiking activity weaker! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd61b1-2dbc-497d-b0d2-62b51f0010c5",
   "metadata": {},
   "source": [
    "## Remove artifacts due to optogenetics stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b6134-009d-4393-b506-e34175946803",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_artifacts =  preprocessing_folder / \"artifacts\"\n",
    "recording_artifact_path = dataset_artifacts / \"preprocessing_artifact_recording.zarr\"\n",
    "events_path = dataset_artifacts / \"opto_stimulation_events.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d149dd-afb1-4d1d-bb73-3a15642d956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_artifacts = si.load_extractor(recording_artifact_path)\n",
    "recording_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325235a-db63-498b-987c-a941a660b0ad",
   "metadata": {},
   "source": [
    "Note: this dataset is from Neuropixels 2.0, which, differently from 1.0, records a wideband signal without hardware filters.\n",
    "\n",
    "Let's load the event information, which include the time, duration, and label for each stimulation event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d9e2df-dfdd-4abb-8caf-d13ac9691f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_artifacts = np.load(events_path)\n",
    "print(events_artifacts)\n",
    "print(events_artifacts.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35240c6-d3fa-4290-a63a-fdb8ae1ca7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_event_time = events_artifacts[\"time\"][0]\n",
    "time_range = [first_event_time - 0.02, first_event_time + 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebecaa23-20cd-4481-a4a1-8f54172efca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_hp_artifacts = spre.highpass_filter(recording_artifacts)\n",
    "recording_ps_artifacts = spre.phase_shift(recording_hp_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280da9ee-89f5-4e63-a31c-cecbe4fe6e46",
   "metadata": {},
   "source": [
    "**NOTE:** since both filtering and phase-shift are linear operations, the order doesn't matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e4bda-c6cc-4ae7-bfa0-16c94fbd95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_layers = dict(\n",
    "    raw=recording_artifacts,\n",
    "    highpass=recording_hp_artifacts,\n",
    "    phase_shift=recording_ps_artifacts\n",
    ")\n",
    "\n",
    "w = sw.plot_traces(recording_layers, time_range=time_range, events=events_artifacts, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c431d5-d73d-445c-b83c-a4fb2cfab5e2",
   "metadata": {},
   "source": [
    "This recording displays some weird patterns of activity, which could affect the spike sorting results.\n",
    "\n",
    "Could they be due to a localized added noisy source? Let's check the frequency content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293eee96-c3e0-455a-9372-175e81600192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = si.get_random_data_chunks(\n",
    "    recording_ps_artifacts,\n",
    "    num_chunks_per_segment=1,\n",
    "    chunk_size=30000,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for tr in data_chunk.T:\n",
    "    p, f = ax.psd(tr, Fs=recording_ps_artifacts.sampling_frequency, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffa9b5-b0d3-4d43-bc6a-8f950b0d5d16",
   "metadata": {},
   "source": [
    "Spotted! There is a nasty noise luckily localized at 10kHz. We can easily remove it with a notch filter (`spre.notch()` funciton):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1b22c-a65b-4f93-afd2-e125db0127d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_artifacts_notch = spre.notch_filter(recording_ps_artifacts, freq=10000, q=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887edd5-e1b3-44bb-be7d-f25940d93037",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = si.get_random_data_chunks(\n",
    "    recording_artifacts_notch,\n",
    "    num_chunks_per_segment=1,\n",
    "    chunk_size=30000,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "for tr in data_chunk.T:\n",
    "    p, f = ax.psd(tr, Fs=recording_artifacts_notch.sampling_frequency, color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788956-b69f-4ba9-a91f-6f17fbe176c1",
   "metadata": {},
   "source": [
    "Now let's try to remove the stimulation artifacts with CMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf807c8-1626-4bc1-bc29-4a66aeec0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_artifacts_cmr = spre.common_reference(recording_artifacts_notch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fd248-4239-4ff8-a387-fc0bf2fa5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_layers = dict(\n",
    "    before_notch=recording_ps_artifacts,\n",
    "    after_notch=recording_artifacts_notch,\n",
    "    cmr_after_notch=recording_artifacts_cmr\n",
    ")\n",
    "\n",
    "w = sw.plot_traces(recording_layers, time_range=time_range, events=events_artifacts, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86643172-c4a0-4942-9f6d-1f7f7d68f831",
   "metadata": {},
   "source": [
    "Unfortunately, CMR is not able to remove the artifacts entirely. Since we know the artifact times, we can blank out the signal in correspondence of the artifacts.\n",
    "\n",
    "This will make the spike sorter life much easier, since it won't have to deal with this weird and large spiky signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27b77a-89aa-40fa-8bc6-8a47495c4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the events_artifact only store the time of the rising edge, we need to fetch the times of the falling edge too:\n",
    "rising_and_falling_times = []\n",
    "for evt in events_artifacts:\n",
    "    t_rising = evt[\"time\"]\n",
    "    t_falling = t_rising + evt[\"duration\"]\n",
    "    rising_and_falling_times.append(t_rising)\n",
    "    rising_and_falling_times.append(t_falling)\n",
    "\n",
    "artifact_sample_indices = np.searchsorted(\n",
    "    recording_artifacts_cmr.get_times(),\n",
    "    rising_and_falling_times\n",
    ")\n",
    "\n",
    "recording_rm_artifacts = spre.remove_artifacts(\n",
    "    recording_artifacts_cmr,\n",
    "    list_triggers=artifact_sample_indices,\n",
    "    mode=\"zeros\",\n",
    "    ms_before=1.5,\n",
    "    ms_after=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12b84c-ee9e-4bd2-9a3a-e17e085c5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_layers = dict(\n",
    "    cmr=recording_artifacts_cmr,\n",
    "    remove=recording_rm_artifacts\n",
    ")\n",
    "\n",
    "w = sw.plot_traces(recording_layers, time_range=time_range, events=events_artifacts, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d31fe-1994-46cb-89e1-a9c5572d32fa",
   "metadata": {},
   "source": [
    "That's all for preprocessing! \n",
    "\n",
    "We have seen how (and why):\n",
    "\n",
    "- preprocess Neuropixels-like recordings to \"destripe\"\n",
    "- apply advanced tools to remove additional noisy sources and artifacts\n",
    "\n",
    "There are several other preprocessing options. For a complete list, checkout our [dedicated documentation page](https://spikeinterface.readthedocs.io/en/latest/modules/preprocessing.html)!\n",
    "\n",
    "Among these is motion correction, which is a very important preprocessing step and will be covered by the next tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
