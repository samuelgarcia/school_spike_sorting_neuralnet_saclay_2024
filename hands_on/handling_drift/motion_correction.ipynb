{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bdff57-b118-4305-978c-7c023a2cef5b",
   "metadata": {},
   "source": [
    "# Motion correction\n",
    "\n",
    "In this tutorial, we will explore the problem of drift registration, i.e. how motion correction algorithms have been applied to extracellular recordings, and how we can use them in SpikeInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf0343-2505-443e-98e4-74026a2b3fc2",
   "metadata": {},
   "source": [
    "## What are the drifts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17cb12-3437-4f36-bdbd-f98acc55652c",
   "metadata": {},
   "source": [
    "The layout of HD probes for in vivo applications usually consists of a long shank (e.g., âˆ¼1 mm for Neuropixels 1.0) to allow the electrodes to span multiple regions of the brain and reach deep structures. Due to the different mechanical properties of the probe and the brain tissue, it is very common to observe a relative movement of the tissue with respect to the probe. This phenomenon is known as drift. The origins and types of such drifts can be diverse. For example, cells are likely to slowly drift from initial positions because of the pressure release in the tissue after an acute probe insertion; abrupt and discontinuous drift events could be caused by sudden rig instabilities and movement artifacts. When a neuron moves with respect to the recording electrodes, its waveforms are distorted (Fig. 1A), challenging the operation of spike sorting algorithms which mainly rely on waveform similarities to cluster different neurons in the recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6214418-283b-471b-9d47-8b993f138b03",
   "metadata": {},
   "source": [
    "![alternative text](drift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba76aa2-279f-49f1-b8f9-ce4800fa065c",
   "metadata": {},
   "source": [
    "## How can we deal with them ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3fc33-f9c0-4879-b908-927d408f42d9",
   "metadata": {},
   "source": [
    "![alternative text](drift2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af216e3c-5c45-45ef-9d3d-5e6ce581fabc",
   "metadata": {},
   "source": [
    "## What do all the methods have in common?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b38772b-54b6-4add-8e16-b82ca73699fe",
   "metadata": {},
   "source": [
    "![alternative text](drift3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4a1bc-9860-4449-8049-4a78befd4512",
   "metadata": {},
   "source": [
    "## What is implemented in SpikeInterface ?\n",
    "See [Garcia et al, 2024](https://doi.org/10.1523/ENEURO.0229-23.2023) for more details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875f014-1987-4b1e-b1a1-5a6d948ffb19",
   "metadata": {},
   "source": [
    "![alternative text](drift4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54de32-486a-40ca-953b-d2fd5f18c0a4",
   "metadata": {},
   "source": [
    "## When should we use such methods?\n",
    "\n",
    "As one can notice, these methods are only designed for high-density probes, with enough channels. Because one needs to interpolate new traces, this methodology can only work if the density of the channels is high-enough. Moreover, these methods are currently only restricted to 1D motion along the depth, thus this is also not suited for plannar arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c580143-595d-4817-a264-b1c8f292ef3d",
   "metadata": {},
   "source": [
    "## Case study: motion estimation and correction on a 1min long recording with rigid sinusoidal drift\n",
    "\n",
    "We can generate artificial data via spikeinterface, using the generate_drifting_recording() function. This function returns a drifting recording, its static equivalent, and the sorting used while generating the spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57026802-3d4b-4d82-bfe1-1e7a217487f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31020f3d-ab75-41c0-b68e-2721a76811ba",
   "metadata": {},
   "source": [
    "Let's start with a classical zigzag motion, starting at t=10s, with a period of 50s. In order to not take too much time, we will restrict ourselves to a 2min long recording, and the motion is first considered as rigid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515bb20b-4b22-4019-b7be-af2876a8a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "zigzag_rigid = [{'drift_mode': 'zigzag', \n",
    "              'non_rigid_gradient': None, \n",
    "              't_start_drift': 10.0, \n",
    "              't_end_drift': None, \n",
    "              'period_s': 50}]\n",
    "\n",
    "\n",
    "\n",
    "static, drifting, sorting = si.generate_drifting_recording(probe_name='Neuropixel-128', \n",
    "                                        seed=23, \n",
    "                                        duration=120, \n",
    "                                        generate_displacement_vector_kwargs={'motion_list' : zigzag_rigid})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028269c2-60a6-4364-9000-700feaaf505c",
   "metadata": {},
   "source": [
    "The default value for the drifting recording is a cropped version of a Neuropixel 2.0 layout, restricted to 128 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c818c02c-1440-4781-b043-2b9bc54b5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc6b4d2-f9d5-40f6-901c-7c0e0dd5a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_probe_map(static)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407225-ced4-49dc-908d-a19ff0798d8f",
   "metadata": {},
   "source": [
    "Now that we are preprocessing expert, we performed all the needed steps as a simple algorithmic pipelines, that will be executed on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c128e6-18f8-496a-97a9-1790e069544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifting_preprocessed = si.highpass_filter(drifting)\n",
    "drifting_preprocessed = si.common_reference(drifting_preprocessed, reference='global')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044abc1b-79d9-4c1c-8ccb-ad2ff38e0882",
   "metadata": {},
   "source": [
    "First, one can get a sense of possible drifts in the recordings by looking at a so-called \"positional raster plot\", i.e. the depth of the spike as function of time. To do so, we need to detect the peaks, and then to localize them in space using the method of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4744039-bd68-4aaf-8cc9-e556bfd4d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "job_kwargs = dict(n_jobs=0.8, chunk_duration='1s', progress_bar=True)\n",
    "peaks = detect_peaks(drifting_preprocessed,  \n",
    "                     method='locally_exclusive',\n",
    "                     detect_threshold=5, \n",
    "                     exclude_sweep_ms=2, \n",
    "                     radius_um=50., \n",
    "                     **job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318793d-25ba-42f7-86e1-31eb5f304569",
   "metadata": {},
   "source": [
    "Let's localize the peaks to get a sense of their putative depths. Several localization methods are available, let's use all the methods to compare. We have:\n",
    "- center_of_mass (a barycenter)\n",
    "- monopolar (a biophysical approximation assuming cells are behaving as monopoles)\n",
    "- grid_convolution (similar to Kilosort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9b65df0-50ca-4798-8891-98cb42c2f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "peak_locations = {}\n",
    "for method in ['monopolar_triangulation', 'grid_convolution', 'center_of_mass']:\n",
    "    peak_locations[method] = localize_peaks(drifting_preprocessed, \n",
    "                                            peaks, \n",
    "                                            method=method, \n",
    "                                            **job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3138e-80be-4122-959b-1369876efe86",
   "metadata": {},
   "source": [
    "We can now display the positional raster plots, for all the aformentionned methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be0fcbde-736b-4a39-9386-da10cbc8d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "fs = drifting_preprocessed.sampling_frequency\n",
    "for method, all_peaks in peak_locations.items():\n",
    "    fig, ax = plt.subplots(ncols=2, \n",
    "                           squeeze=False, \n",
    "                           figsize=(5, 5), \n",
    "                           sharey=True)\n",
    "    ax[0, 0].scatter(peaks['sample_index'] / fs, \n",
    "                     all_peaks['y'], \n",
    "                     color='k', \n",
    "                     marker='.',  \n",
    "                     alpha=0.002)\n",
    "    ax[0, 0].set_title(method)\n",
    "    si.plot_probe_map(drifting_preprocessed, ax=ax[0, 1])\n",
    "    ax[0, 1].scatter(all_peaks['x'], \n",
    "                     all_peaks['y'], \n",
    "                     color='purple', alpha=0.002)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27be5b5-a09d-4c2f-b591-3bcd4adbeb3c",
   "metadata": {},
   "source": [
    "## Motion estimation\n",
    "\n",
    "Now, we have all the ingredients to estimate the motion in this recording. Motion estimation is a complex pre-processing step, as it requires to detect peaks, estimate motion, and then compensate for the motion. As shown in previous figures, all these steps have various possibilities. This is why SpikeInterface offers a high-level correct_motion() function with some custom presets, to let you decide what you want to do.\n",
    "Among these presets, we have:\n",
    "- kilosort_like: detect peaks, then localize via grid_convolution, then estimate the motion via a template approach before interpolating via kriging\n",
    "- nonrigid_accurate: detect peaks, then localize via monopolar_approximation (slow but more accurate), then estimate the motion via a decentralized approach before interpolating via kriging\n",
    "- nonrigid_fast_and_accurate: detect peaks, then localize via grid_convolution, then estimate the motion via a decentralized approach before interpolating via kriging\n",
    "\n",
    "Since the recording is not too long, let's try all methods to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88437c5d-8ceb-44c8-9638-92162405912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motions_corrected = {}\n",
    "for method in ['kilosort_like', 'nonrigid_accurate', 'nonrigid_fast_and_accurate']:\n",
    "    motions_corrected[method] = si.correct_motion(drifting_preprocessed, \n",
    "                                        preset=method, \n",
    "                                        interpolate_motion_kwargs={'border_mode' : 'force_extrapolate'},\n",
    "                                        folder=method, \n",
    "                                        **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31d2ddb3-1fc6-4399-b471-ddf658797c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['kilosort_like', 'nonrigid_accurate', 'nonrigid_fast_and_accurate']:\n",
    "    motion_info = si.load_motion_info(method)\n",
    "    si.plot_motion(motion_info, \n",
    "                   motions_corrected[method], \n",
    "                   amplitude_cmap='inferno', \n",
    "                   color_amplitude=True, \n",
    "                   figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92eeb57c-50a0-4cb0-b061-2f4a77ee1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'nonrigid_fast_and_accurate'\n",
    "motion_info = si.load_motion_info(method)\n",
    "%matplotlib widget\n",
    "si.plot_traces({'no correction' : drifting_preprocessed, \n",
    "                'correction' : motions_corrected[method]}, \n",
    "                backend='ipywidgets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96735533-d49c-46d9-a8f0-f34afd030806",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "You can redo the same and estimate the motion in different cases:\n",
    "- with abrupt, discontinuous drifts\n",
    "- with non-rigid-drifts\n",
    "- a combination of both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0b7680-1e16-4dda-a5b3-80ce60def021",
   "metadata": {},
   "outputs": [],
   "source": [
    "zigzag_nonrigid = [{'drift_mode': 'zigzag', \n",
    "                       'non_rigid_gradient': 0.5, \n",
    "                       't_start_drift': 10.0, \n",
    "                       't_end_drift': None, \n",
    "                       'period_s': 50}]\n",
    "\n",
    "rigid_bumps = [{'drift_mode': 'bump', \n",
    "                    'non_rigid_gradient': None, \n",
    "                    't_start_drift': 10.0, \n",
    "                    't_end_drift': None, \n",
    "                    'period_s': 50}]\n",
    "\n",
    "combined_motions = zigzag_nonrigid + rigid_bumps\n",
    "\n",
    "static, drifting, sorting = si.generate_drifting_recording(probe_name='Neuropixel-128', \n",
    "                                    seed=23, \n",
    "                                    duration=120, \n",
    "                                    generate_displacement_vector_kwargs={'motion_list' : combined_motions})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
