{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following lines to be sure that we have the latest versio of neuroconv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/CatalystNeuro/roiextractors@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NWB and Spikeinterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NWB Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to slides](https://docs.google.com/presentation/d/1DwUEKQrUkTLi2hm4RwV1egWnJ3wsGUI973Zku-HA-zg/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurconv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Spikeinterface objects to in-memory NWB file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create an NWBFile. We will work in-memory. That is, we will create an NWBFile object that is not associated with a file on disk.\n",
    "We will see later how to write this NWBFile to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.tools.spikeinterface import add_electrical_series\n",
    "from pynwb import NWBFile\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "session_start_time = datetime.datetime.now()  # The date of today\n",
    "session_description = \"A test NWB file with electrical series.\"\n",
    "identifier = \"A unique identifier\"\n",
    "\n",
    "nwbfile = NWBFile(session_description=session_description, session_start_time=session_start_time, identifier=identifier)\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now be adding Spikeinterface objects to the NWBFile. Let's create artificial data to demostrate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.core import generate_ground_truth_recording\n",
    "\n",
    "\n",
    "recording, sorting = generate_ground_truth_recording(num_channels=8, num_units=3, durations=[60*10.0], seed=0,)\n",
    "\n",
    "recording = recording.rename_channels(new_channel_ids=[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]) \n",
    "sorting = sorting.rename_units(new_unit_ids=[\"Unit A\", \"Unit B\", \"Unit C\"])                                  \n",
    "\n",
    "# Add new properties to the recording and sorting\n",
    "recording.set_property(key=\"a_channel_property\", values=[f\"property {channel}\" for channel in recording.get_channel_ids()])\n",
    "recording.set_property(key=\"brain_area\", values=[f\"Area {channel}\" for channel in recording.get_channel_ids()])\n",
    "sorting.set_property(key=\"a_unit_property\", values=[\"property Unit A\", \"property Unit B\", \"property Unit C\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface.plotting import plot_probe\n",
    "probe = recording.get_probe()\n",
    "\n",
    "plot_probe(probe);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.tools.spikeinterface import add_recording\n",
    "\n",
    "add_recording(recording=recording, nwbfile=nwbfile)\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.electrodes.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.preprocessing import bandpass_filter\n",
    "\n",
    "filtered_recording = bandpass_filter(recording, freq_min=1, freq_max=300)\n",
    "\n",
    "add_electrical_series(recording=filtered_recording, nwbfile=nwbfile, write_as=\"lfp\")\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroconv.tools.spikeinterface import add_sorting\n",
    "\n",
    "\n",
    "add_sorting(sorting=sorting, nwbfile=nwbfile)\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.units.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we write to the NWBFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this to a file\n",
    "from pathlib import Path\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "nwb_file_path = Path.cwd() / \"from_memory_to_nwbfile.nwb\"\n",
    "with NWBHDF5IO(path=nwb_file_path, mode=\"w\") as io:\n",
    "    io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing recording and sorting objects directly to NWB\n",
    "\n",
    "Another way of working is writing the files directly to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "from neuroconv.tools.spikeinterface import write_recording\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "nwbfile_path = Path.cwd() / \"spikeinterface_to_nwb.nwb\"\n",
    "\n",
    "metadata = {\n",
    "    \"NWBFile\": {\"session_description\": \"A test NWB file with electrical series.\", \"identifier\": \"A unique identifier\", \"session_start_time\": datetime.now()},\n",
    "    \"Subject\": {\"subject_id\": \"spiky_mouse\" , \"age\": \"3 months\", \"species\": \"Mus musculus\", \"sex\": \"M\"},\n",
    "    \"Ecephys\": {\"device\": {\"name\": \"RecordingDevice\"}}\n",
    "    }\n",
    "\n",
    "write_recording(recording=recording, nwbfile_path=nwbfile_path, metadata=metadata, overwrite=True, verbose=False)\n",
    "\n",
    "# Load the NWB file\n",
    "io = NWBHDF5IO(path=nwb_file_path, mode=\"r\")\n",
    "nwbfile = io.read()\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will close the file, then we will append the sorting object to the NWBFile on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from neuroconv.tools.spikeinterface import write_sorting\n",
    "\n",
    "# We confirm that the file that we created is stil there using pathlib\n",
    "assert_msg = \"Something went wrong, the file does not exist, re-run the previous cells to create the file\"\n",
    "assert Path(nwbfile_path).exists(), assert_msg\n",
    "\n",
    "\n",
    "write_sorting(sorting=sorting, nwbfile_path=nwbfile_path, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = NWBHDF5IO(path=nwb_file_path, mode=\"r\")\n",
    "nwbfile = io.read()\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NWB files in Spikeinterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the file that we created from memory as it has two electrical series and a sorting object.\n",
    "First, we will confirm that our file has to electrical series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.extractors import NwbRecordingExtractor\n",
    "\n",
    "nwbfile_file_path = Path.cwd() / \"from_memory_to_nwbfile.nwb\"\n",
    "available_electrical_series = NwbRecordingExtractor.fetch_available_electrical_series_paths(file_path=nwb_file_path)\n",
    "available_electrical_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = NwbRecordingExtractor(file_path=nwb_file_path, electrical_series_path=\"acquisition/ElectricalSeriesRaw\")\n",
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface.plotting import plot_probe\n",
    "probe = recording.get_probe()\n",
    "\n",
    "plot_probe(probe);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming objects from NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from spikeinterface.extractors import NwbRecordingExtractor\n",
    "\n",
    "client = DandiAPIClient.for_dandi_instance(\"dandi\")\n",
    "\n",
    "dandiset_id = \"000409\"\n",
    "dandiset = client.get_dandiset(dandiset_id)\n",
    "\n",
    "\n",
    "#asset_path = dandiset_paths_with_ecephys[3]\n",
    "asset_path = \"sub-KS042/sub-KS042_ses-8c552ddc-813e-4035-81cc-3971b57efe65_behavior+ecephys+image.nwb\"\n",
    "recording_asset = dandiset.get_asset_by_path(path=asset_path)\n",
    "url = recording_asset.get_content_url(follow_redirects=True, strip_query=True)\n",
    "file_path = url\n",
    "\n",
    "electrical_series_path = \"acquisition/ElectricalSeriesAp00\"\n",
    "recording = NwbRecordingExtractor(file_path=file_path, stream_mode=\"remfile\", electrical_series_path=electrical_series_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from spikeinterface.widgets import plot_traces\n",
    "\n",
    "\n",
    "plot_traces(recording=recording, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.widgets import plot_rasters\n",
    "\n",
    "\n",
    "plot_rasters(sorting=sorting, backend=\"matplotlib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroconv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
